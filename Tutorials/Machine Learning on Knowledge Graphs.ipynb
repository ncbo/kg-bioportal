{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4c6c8a",
   "metadata": {},
   "source": [
    "# KG-Hub: Machine Learning on Knowledge Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ff130",
   "metadata": {},
   "source": [
    "This walkthrough provides a basic introduction to preparing KG-Hub projects for graph-based machine learning and analysis. It assumes you have already set up a KG-Hub project and have produced a merged graph. The graph should be in the `/data/merged/` directory, named `merged-kg.tar.gz`, and be in KGX TSV format.\n",
    "\n",
    "If the merged graph is somewhere else, change the value for `merged_graph_path` below. Otherwise, just run that code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2356de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_graph_path = \"../data/merged/merged-kg.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b680a",
   "metadata": {},
   "source": [
    "If you don't already have a graph and just want to dive in, run this next block. It will download a copy of the MONDO disease ontology graph from KG-OBO. This is not the most exciting input, but it's comparatively small and will still work in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://kg-hub.berkeleybop.io/kg-obo/mondo/2022-02-04/mondo_kgx_tsv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf15727",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_graph_path = \"./mondo_kgx_tsv.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec58b04",
   "metadata": {},
   "source": [
    "## Loading and processing graphs with GraPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab8ccc3",
   "metadata": {},
   "source": [
    "The [Graph Processing and Embedding (GraPE) package](https://github.com/AnacletoLAB/grape) is a comprehensive toolbox for loading, processing, describing, and otherwise learning from graphs. It has two primary components: Ensmallen, which handles graph processing, and Embiggen, which produces embeddings. Working with large, complex graphs can be very computationally intensive, so the GraPE tools use a variety of strategies to optimize efficiency. They also work very well with KG-Hub graphs!\n",
    "\n",
    "[The full documentation for GraPE is here.](https://anacletolab.github.io/grape/index.html) You'll see that it offers a sizable collection of functions, so feel free to explore. There are also [tutorial notebooks](https://github.com/AnacletoLAB/grape/tree/main/tutorials) to peruse. For now, let's get GraPE ready, load a graph, and learn about its features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0670ffd",
   "metadata": {},
   "source": [
    "First, install GraPE and a variety of other dependencies with `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install grape -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd97037",
   "metadata": {},
   "source": [
    "Every graph in Ensmallen is loaded as a `Graph` object, so we import that class (and `random`, because we'll use it later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b04a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensmallen import Graph\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c8951",
   "metadata": {},
   "source": [
    "Decompress the graph, as Ensmallen will expect separate node and edge files. If your node and edge filenames differ from the values for `merged_node_filename` and `merged_edge_filename` below, please change them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvzf $merged_graph_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519dcc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_node_filename = \"merged-kg_nodes.tsv\"\n",
    "merged_edge_filename = \"merged-kg_edges.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ef775",
   "metadata": {},
   "source": [
    "Load the graph with Ensmallen's `from_csv` (don't worry, we will tell it that these are tsv files, not csv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58e6ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a_big_graph = Graph.from_csv(\n",
    "    node_path=merged_node_filename,\n",
    "    edge_path=merged_edge_filename,\n",
    "    node_list_separator=\"\\t\",\n",
    "    edge_list_separator=\"\\t\",\n",
    "    node_list_header=True,  # Always true for KG-Hub KGs\n",
    "    edge_list_header=True,  # Always true for KG-Hub KGs\n",
    "    nodes_column='id',  # Always true for KG-Hub KGs\n",
    "    node_list_node_types_column='category',  # Always true for KG-Hub KGs\n",
    "    sources_column='subject',  # Always true for KG-Hub KGs\n",
    "    destinations_column='object',  # Always true for KG-Hub KGs\n",
    "    directed=False,\n",
    "    name=\"A_Big_Graph\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "a_big_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e4886",
   "metadata": {},
   "source": [
    "Great, now we've loaded a graph and have some general ideas about its contents.\n",
    "\n",
    "We can retrieve the total count of connected nodes (i.e., exclude all disconnected nodes from the count):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53532051",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_big_graph.get_connected_nodes_number()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a92a27",
   "metadata": {},
   "source": [
    "We can also retrieve a random array of nodes to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00265604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will output a numpy array.\n",
    "# Set random_state to a specific value to get the same result reproducibly\n",
    "random_int = random.randint(10000,99999)\n",
    "some_nodes = a_big_graph.get_random_nodes(number_of_nodes_to_sample=10, random_state=random_int)\n",
    "some_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c192931",
   "metadata": {},
   "source": [
    "The nodes are represented as integers for the sake of efficiency. If you'd prefer names, we can get those too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f45849",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_node_names = []\n",
    "for node_id in some_nodes:\n",
    "    node_name = a_big_graph.get_node_name_from_node_id(node_id)\n",
    "    all_node_names.append((node_id,node_name))\n",
    "all_node_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c9f2e",
   "metadata": {},
   "source": [
    "We can see how many neighbors each node has (i.e., its degree):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1556897",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_node_degrees = []\n",
    "for node_id in some_nodes:\n",
    "    node_degree = a_big_graph.get_node_degree_from_node_id(node_id)\n",
    "    all_node_degrees.append((node_id,node_degree))\n",
    "all_node_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d03776",
   "metadata": {},
   "source": [
    "We may also retrieve node types, starting with the node ID numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_node_types = []\n",
    "for node_id in some_nodes:\n",
    "    one_node_type = a_big_graph.get_node_type_names_from_node_id(node_id)\n",
    "    if one_node_type not in all_node_types:\n",
    "        all_node_types.append(one_node_type)\n",
    "all_node_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d438df",
   "metadata": {},
   "source": [
    "Finally, let's complete a task in preparation for the next section: assembling holdout data and sets of negative edges. Ensmallen can handle both of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save an 80/20 training/validation split of the edges in the input graph.\n",
    "train_edge_path = merged_edge_filename + \".train\"\n",
    "valid_edge_path = merged_edge_filename + \".valid\"\n",
    "\n",
    "train_edge_graph, valid_edge_graph = a_big_graph.random_holdout(train_size=0.8)\n",
    "train_edge_graph.dump_edges(train_edge_path, edges_type_column='predicate')\n",
    "valid_edge_graph.dump_edges(valid_edge_path, edges_type_column='predicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the graph of negatives.\n",
    "negative_graph = a_big_graph.sample_negatives(a_big_graph.get_edges_number()) # Just as many negative examples as positive examples\n",
    "negative_graph = negative_graph.drop_disconnected_nodes()\n",
    "negative_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e05f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above, this will save training and validation edge lists.\n",
    "neg_train_edge_path = merged_edge_filename + \".neg_train\"\n",
    "neg_valid_edge_path = merged_edge_filename + \".neg_valid\"\n",
    "\n",
    "neg_train_edge_graph, neg_valid_edge_graph = negative_graph.random_holdout(train_size=0.8)\n",
    "neg_train_edge_graph.dump_edges(neg_train_edge_path, edges_type_column='predicate')\n",
    "neg_valid_edge_graph.dump_edges(neg_valid_edge_path, edges_type_column='predicate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba34ad5",
   "metadata": {},
   "source": [
    "## Generating embeddings and building classifiers with NEAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1491b",
   "metadata": {},
   "source": [
    "The [NEAT](https://github.com/Knowledge-Graph-Hub/NEAT) package provides a way to define graph machine learning tasks with a single configuration file. We'll generate such a file here, then run NEAT to produce embeddings and a link prediction classifier.\n",
    "\n",
    "We'll start by defining some basic parameters, largely based on what we did in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbeff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get NEAT on Pypi so we can pip install it here\n",
    "# In the meantime, install from GH with\n",
    "# git clone https://github.com/Knowledge-Graph-Hub/NEAT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b93008",
   "metadata": {},
   "outputs": [],
   "source": [
    "directed = False # Yes, this is technically a directed network, but we'll treat it as undirected\n",
    "node_path = merged_node_filename # Positive training nodes\n",
    "edge_path = train_edge_path # Positive training edges\n",
    "#valid_edge_path - we've already defined this above\n",
    "#neg_train_edge_path - we've already defined this above\n",
    "#neg_valid_edge_path - we've already defined this above\n",
    "\n",
    "# Embedding parameters\n",
    "embedding_file_name = \"embeddings.tsv\"\n",
    "embedding_history_file_name = \"embedding_history.json\"\n",
    "node_embedding_method_name = \"CBOW\" # one of 'CBOW', 'GloVe', 'SkipGram', 'Siamese', 'TransE', 'SimplE', 'TransH', 'TransR'\n",
    "walk_length = 10 # typically 100 or so\n",
    "batch_size = 128 # typically 512 or more\n",
    "window_size = 4\n",
    "iterations = 5 # typically 20 or more\n",
    "\n",
    "# Classifier parameters - NEAT can build multiple classifier types in one run, if specified in the configuration file\n",
    "edge_method = \"Average\" # one of EdgeTransformer.methods: Hadamard, Sum, Average, L1, AbsoluteL1, L2, or alternatively a lambda\n",
    "classifier_type = \"Logistic Regression\"\n",
    "classifier_model_outfile = \"model_lr\"\n",
    "classifier_model_type = \"sklearn.linear_model.LogisticRegression\"\n",
    "classifier_model_random_state = 42\n",
    "classifier_model_max_iter = 1000\n",
    "\n",
    "# Output parameters\n",
    "output_directory = \"./\"\n",
    "config_filename = \"scallops.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "outstring = f\"\"\"\n",
    "graph_data:\n",
    "  graph:\n",
    "    directed: {directed}\n",
    "    node_path: {node_path}\n",
    "    edge_path: {edge_path}\n",
    "    verbose: True\n",
    "    nodes_column: 'id'\n",
    "    node_list_node_types_column: 'category'\n",
    "    default_node_type: 'biolink:NamedThing'\n",
    "    sources_column: 'subject'\n",
    "    destinations_column: 'object'\n",
    "    default_edge_type: 'biolink:related_to'\n",
    "  pos_validation:\n",
    "    edge_path: {valid_edge_path}\n",
    "  neg_training:\n",
    "    edge_path: {neg_train_edge_path}\n",
    "  neg_validation:\n",
    "    edge_path: {neg_valid_edge_path}\n",
    "\n",
    "embeddings:\n",
    "  embedding_file_name: {embedding_file_name}\n",
    "  embedding_history_file_name: {embedding_history_file_name}\n",
    "  node_embedding_params:\n",
    "      node_embedding_method_name: {node_embedding_method_name}\n",
    "      walk_length: {walk_length}\n",
    "      batch_size: {batch_size}\n",
    "      window_size: {window_size}\n",
    "      return_weight: 1.0\n",
    "      explore_weight: 1.0\n",
    "      iterations: {iterations}\n",
    "      use_mirrored_strategy: False\n",
    "\n",
    "  tsne:\n",
    "    tsne_file_name: tsne.png\n",
    "\n",
    "classifier:\n",
    "  edge_method: {edge_method}\n",
    "  classifiers:\n",
    "    - type: {classifier_type}\n",
    "      model:\n",
    "        outfile: {classifier_model_outfile}\n",
    "        type: {classifier_model_type}\n",
    "        parameters:\n",
    "          random_state: {classifier_model_random_state}\n",
    "          max_iter: {classifier_model_max_iter}\n",
    "\n",
    "output_directory: {output_directory}\n",
    "\"\"\"\n",
    "print(outstring)\n",
    "with open(config_filename, \"w\") as outfile:\n",
    "    outfile.write(outstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!neat run --config $config_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5770fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='tsne.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
